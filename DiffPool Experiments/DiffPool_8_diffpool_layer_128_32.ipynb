{"cells":[{"cell_type":"markdown","metadata":{"id":"gbDron_rv4FZ"},"source":["# Args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YuQSONW4v7Fw"},"outputs":[],"source":["args = {\n","        'device': 0,\n","        'num_layer': 3,\n","        'emb_dim': 256,\n","        'drop_ratio': 0.5,\n","        'batch_size': 64,\n","        'lr': 0.01,\n","        'epochs': 50,\n","        'num_vocab': 5000,\n","        'max_seq_len': 5,\n","        'diff_pool_layers': [(128,5), (32,3)],\n","        'max_num_nodes': 512,\n","        'random_split': False,\n","        'dataset': \"ogbg-code2\",\n","        'num_workers': 0,\n","        'model_save_path': \"best_model_params\",\n","        'eval_results_path': 'eval_results'\n","    }"]},{"cell_type":"markdown","metadata":{"id":"xLMap4xcvGwG"},"source":["# Setting up the dependencies and download the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144325,"status":"ok","timestamp":1701867632839,"user":{"displayName":"昂国昊","userId":"00863862249147242163"},"user_tz":480},"id":"70NcYDLQ6rop","outputId":"cf23cc4e-f325-4ccd-c074-c8c85a6b7d20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ogb\n","  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu118)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n","Collecting outdated>=0.2.0 (from ogb)\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n","Collecting littleutils (from outdated>=0.2.0->ogb)\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=d3cc7728008ec198d0cff9c78fd3f615018ba1daf92e9ea8a30200a640adfb35\n","  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n","Successfully built littleutils\n","Installing collected packages: littleutils, outdated, ogb\n","Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n","Collecting torch_geometric\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.4.0\n","1.3.6\n","2.1.0+cu118\n","Downloading http://snap.stanford.edu/ogb/data/graphproppred/code2.zip\n"]},{"name":"stderr","output_type":"stream","text":["Downloaded 0.91 GB: 100%|██████████| 934/934 [01:01<00:00, 15.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting dataset/code2.zip\n"]},{"name":"stderr","output_type":"stream","text":["Processing...\n"]},{"name":"stdout","output_type":"stream","text":["Loading necessary files...\n","This might take a while.\n","Processing graphs...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 452741/452741 [00:01<00:00, 341403.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Converting graphs into PyG objects...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 452741/452741 [00:21<00:00, 21136.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving...\n"]},{"name":"stderr","output_type":"stream","text":["Done!\n"]}],"source":["!pip install ogb\n","!pip install torch_geometric\n","!python -c \"import ogb; print(ogb.__version__)\"\n","\n","import os\n","from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n","from torch_geometric.loader import DataLoader\n","import torch\n","import pandas as pd\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm\n","print(torch.__version__)\n","\n","# The PyG built-in GCNConv\n","from torch_geometric.nn import GCNConv\n","\n","import torch_geometric.transforms as T\n","from torch_geometric.nn import global_add_pool, global_mean_pool\n","\n","dataset = PygGraphPropPredDataset(name = \"ogbg-code2\")"]},{"cell_type":"markdown","metadata":{"id":"6bo9YEJuQ6P4"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yxo9TsBKQ8jy"},"outputs":[],"source":["from collections import Counter\n","import numpy as np\n","import torch\n","\n","class ASTNodeEncoder(torch.nn.Module):\n","    '''\n","        Input:\n","            x: default node feature. the first and second column represents node type and node attributes.\n","            depth: The depth of the node in the AST.\n","\n","        Output:\n","            emb_dim-dimensional vector\n","\n","    '''\n","    def __init__(self, emb_dim, num_nodetypes, num_nodeattributes, max_depth):\n","        super(ASTNodeEncoder, self).__init__()\n","\n","        self.max_depth = max_depth\n","\n","        self.type_encoder = torch.nn.Embedding(num_nodetypes, emb_dim)\n","        self.attribute_encoder = torch.nn.Embedding(num_nodeattributes, emb_dim)\n","        self.depth_encoder = torch.nn.Embedding(self.max_depth + 1, emb_dim)\n","\n","\n","    def forward(self, x, depth):\n","        depth[depth > self.max_depth] = self.max_depth\n","        return self.type_encoder(x[:,0]) + self.attribute_encoder(x[:,1]) + self.depth_encoder(depth)\n","\n","\n","\n","def get_vocab_mapping(seq_list, num_vocab):\n","    '''\n","        Input:\n","            seq_list: a list of sequences\n","            num_vocab: vocabulary size\n","        Output:\n","            vocab2idx:\n","                A dictionary that maps vocabulary into integer index.\n","                Additioanlly, we also index '__UNK__' and '__EOS__'\n","                '__UNK__' : out-of-vocabulary term\n","                '__EOS__' : end-of-sentence\n","\n","            idx2vocab:\n","                A list that maps idx to actual vocabulary.\n","\n","    '''\n","\n","    vocab_cnt = {}\n","    vocab_list = []\n","    for seq in seq_list:\n","        for w in seq:\n","            if w in vocab_cnt:\n","                vocab_cnt[w] += 1\n","            else:\n","                vocab_cnt[w] = 1\n","                vocab_list.append(w)\n","\n","    cnt_list = np.array([vocab_cnt[w] for w in vocab_list])\n","    topvocab = np.argsort(-cnt_list, kind = 'stable')[:num_vocab]\n","\n","    print('Coverage of top {} vocabulary:'.format(num_vocab))\n","    print(float(np.sum(cnt_list[topvocab]))/np.sum(cnt_list))\n","\n","    vocab2idx = {vocab_list[vocab_idx]: idx for idx, vocab_idx in enumerate(topvocab)}\n","    idx2vocab = [vocab_list[vocab_idx] for vocab_idx in topvocab]\n","\n","    # print(topvocab)\n","    # print([vocab_list[v] for v in topvocab[:10]])\n","    # print([vocab_list[v] for v in topvocab[-10:]])\n","\n","    vocab2idx['__UNK__'] = num_vocab\n","    idx2vocab.append('__UNK__')\n","\n","    vocab2idx['__EOS__'] = num_vocab + 1\n","    idx2vocab.append('__EOS__')\n","\n","    # test the correspondence between vocab2idx and idx2vocab\n","    for idx, vocab in enumerate(idx2vocab):\n","        assert(idx == vocab2idx[vocab])\n","\n","    # test that the idx of '__EOS__' is len(idx2vocab) - 1.\n","    # This fact will be used in decode_arr_to_seq, when finding __EOS__\n","    assert(vocab2idx['__EOS__'] == len(idx2vocab) - 1)\n","\n","    return vocab2idx, idx2vocab\n","\n","def augment_edge(data):\n","    '''\n","        Input:\n","            data: PyG data object\n","        Output:\n","            data (edges are augmented in the following ways):\n","                data.edge_index: Added next-token edge. The inverse edges were also added.\n","                data.edge_attr (torch.Long):\n","                    data.edge_attr[:,0]: whether it is AST edge (0) for next-token edge (1)\n","                    data.edge_attr[:,1]: whether it is original direction (0) or inverse direction (1)\n","    '''\n","\n","    ##### AST edge\n","    edge_index_ast = data.edge_index\n","    edge_attr_ast = torch.zeros((edge_index_ast.size(1), 2))\n","\n","    ##### Inverse AST edge\n","    edge_index_ast_inverse = torch.stack([edge_index_ast[1], edge_index_ast[0]], dim = 0)\n","    edge_attr_ast_inverse = torch.cat([torch.zeros(edge_index_ast_inverse.size(1), 1), torch.ones(edge_index_ast_inverse.size(1), 1)], dim = 1)\n","\n","\n","    ##### Next-token edge\n","\n","    ## Obtain attributed nodes and get their indices in dfs order\n","    # attributed_node_idx = torch.where(data.node_is_attributed.view(-1,) == 1)[0]\n","    # attributed_node_idx_in_dfs_order = attributed_node_idx[torch.argsort(data.node_dfs_order[attributed_node_idx].view(-1,))]\n","\n","    ## Since the nodes are already sorted in dfs ordering in our case, we can just do the following.\n","    attributed_node_idx_in_dfs_order = torch.where(data.node_is_attributed.view(-1,) == 1)[0]\n","\n","    ## build next token edge\n","    # Given: attributed_node_idx_in_dfs_order\n","    #        [1, 3, 4, 5, 8, 9, 12]\n","    # Output:\n","    #    [[1, 3, 4, 5, 8, 9]\n","    #     [3, 4, 5, 8, 9, 12]\n","    edge_index_nextoken = torch.stack([attributed_node_idx_in_dfs_order[:-1], attributed_node_idx_in_dfs_order[1:]], dim = 0)\n","    edge_attr_nextoken = torch.cat([torch.ones(edge_index_nextoken.size(1), 1), torch.zeros(edge_index_nextoken.size(1), 1)], dim = 1)\n","\n","\n","    ##### Inverse next-token edge\n","    edge_index_nextoken_inverse = torch.stack([edge_index_nextoken[1], edge_index_nextoken[0]], dim = 0)\n","    edge_attr_nextoken_inverse = torch.ones((edge_index_nextoken.size(1), 2))\n","\n","\n","    data.edge_index = torch.cat([edge_index_ast, edge_index_ast_inverse, edge_index_nextoken, edge_index_nextoken_inverse], dim = 1)\n","    data.edge_attr = torch.cat([edge_attr_ast,   edge_attr_ast_inverse, edge_attr_nextoken,  edge_attr_nextoken_inverse], dim = 0)\n","\n","    return data\n","\n","def encode_y_to_arr(data, vocab2idx, max_seq_len):\n","    '''\n","    Input:\n","        data: PyG graph object\n","        output: add y_arr to data\n","    '''\n","\n","    # PyG >= 1.5.0\n","    seq = data.y\n","\n","    # PyG = 1.4.3\n","    # seq = data.y[0]\n","\n","    data.y_arr = encode_seq_to_arr(seq, vocab2idx, max_seq_len)\n","\n","    return data\n","\n","def encode_seq_to_arr(seq, vocab2idx, max_seq_len):\n","    '''\n","    Input:\n","        seq: A list of words\n","        output: add y_arr (torch.Tensor)\n","    '''\n","\n","    augmented_seq = seq[:max_seq_len] + ['__EOS__'] * max(0, max_seq_len - len(seq))\n","    return torch.tensor([[vocab2idx[w] if w in vocab2idx else vocab2idx['__UNK__'] for w in augmented_seq]], dtype = torch.long)\n","\n","\n","def decode_arr_to_seq(arr, idx2vocab):\n","    '''\n","        Input: torch 1d array: y_arr\n","        Output: a sequence of words.\n","    '''\n","\n","\n","    eos_idx_list = torch.nonzero(arr == len(idx2vocab) - 1, as_tuple=False) # find the position of __EOS__ (the last vocab in idx2vocab)\n","    if len(eos_idx_list) > 0:\n","        clippted_arr = arr[: torch.min(eos_idx_list)] # find the smallest __EOS__\n","    else:\n","        clippted_arr = arr\n","\n","    return list(map(lambda x: idx2vocab[x], clippted_arr.cpu()))\n"]},{"cell_type":"markdown","metadata":{"id":"8aQf6gJSv9lx"},"source":["# Define GNN and DiffPool"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OWe_CB0ywFN4"},"outputs":[],"source":["from torch_geometric.nn import dense_diff_pool, global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set, DenseGCNConv\n","from torch_geometric.utils import to_dense_batch, to_dense_adj\n","import torch.nn.functional as F\n","\n","# The generic GCN used by different layers of DiffPool\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n","        super(GCN, self).__init__()\n","\n","        # GCN layers\n","        self.convs = torch.nn.ModuleList()\n","        self.convs.extend([DenseGCNConv(hidden_dim, hidden_dim) for i in range(num_layers-1)])\n","        self.convs.append(DenseGCNConv(hidden_dim, output_dim))\n","\n","        # Batch norm\n","        self.bns = torch.nn.ModuleList()\n","        self.bns.extend([torch.nn.BatchNorm1d(hidden_dim) for i in range(num_layers-1)])\n","\n","        # Log Softmax\n","        self.softmax = torch.nn.LogSoftmax(dim=1)\n","\n","        # Probability of an element getting zeroed\n","        self.dropout = dropout\n","\n","    def forward(self, x, adj):\n","        for i in range(len(self.convs)-1):\n","          x = self.convs[i](x, adj)\n","          x = self.bns[i](x.transpose(1,2))\n","          x = x.transpose(1,2)\n","          x = F.relu(x)\n","          x = F.dropout(x, p=self.dropout, training=self.training)\n","        out = self.convs[-1](x, adj)\n","\n","        return out\n","\n","# A DiffPool layer that takes in a graph and pool the nodes to produce a\n","# smaller graph\n","class DiffPool(torch.nn.Module):\n","    def __init__(self, gnn_embed, gnn_pool, number_of_nodes_out):\n","        super(DiffPool, self).__init__()\n","        self.gnn_embed = gnn_embed\n","        self.gnn_pool = gnn_pool\n","        self.number_of_nodes_out = number_of_nodes_out\n","\n","    def forward(self, x, adj, mask=None):\n","        # Compute embeddings and assignment matrix with GNNs.\n","        z = self.gnn_embed(x, adj)\n","        s = self.gnn_pool(x, adj)\n","\n","        # Use the DiffPool to get pooled graph.\n","        x, adj, l1, e1 = dense_diff_pool(z, adj, s, mask)\n","\n","        return x, adj\n","\n","\n","\n","# The top-level abstraction for a composition of networks that takes in a batch\n","# of data and proudces a prediction\n","class GNN(torch.nn.Module):\n","    def __init__(self, num_vocab, max_seq_len, node_encoder, gnn_num_layers = 3, diff_pool_node_number_list=[(50, 3), (10, 3), (3, 3)], emb_dim = 300, drop_ratio = 0.5, graph_pooling = \"mean\", max_num_nodes=1000):\n","        super(GNN, self).__init__()\n","        self.drop_ratio = drop_ratio\n","        self.emb_dim = emb_dim\n","        self.num_vocab = num_vocab\n","        self.max_seq_len = max_seq_len\n","        self.graph_pooling = graph_pooling\n","        self.dropout_ratio = drop_ratio\n","        self.max_num_nodes = max_num_nodes\n","\n","        if gnn_num_layers < 2:\n","            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n","\n","\n","        self.node_encoder = node_encoder\n","\n","        # Define the DiffPool layers\n","        self.diff_pool_layers = torch.nn.ModuleList()\n","        for number_of_nodes_out, gcn_layer_num in diff_pool_node_number_list:\n","            gnn_embed = GCN(input_dim=emb_dim, hidden_dim=emb_dim, output_dim=emb_dim, num_layers=gcn_layer_num, dropout=drop_ratio)\n","            gnn_pool = GCN(input_dim=emb_dim, hidden_dim=emb_dim, output_dim=number_of_nodes_out, num_layers=gcn_layer_num, dropout=drop_ratio)\n","            diff_pool_layer = DiffPool(gnn_embed=gnn_embed, gnn_pool=gnn_pool, number_of_nodes_out=number_of_nodes_out)\n","            self.diff_pool_layers.append(diff_pool_layer)\n","\n","        # Define the final GNN that takes the output of the final\n","        self.final_gnn = GCN(input_dim=emb_dim, hidden_dim=emb_dim, output_dim=emb_dim, num_layers=gnn_num_layers, dropout=drop_ratio)\n","\n","        # Pooling function to generate whole-graph embeddings\n","        if self.graph_pooling == \"sum\":\n","            self.pool = global_add_pool\n","        elif self.graph_pooling == \"mean\":\n","            self.pool = global_mean_pool\n","        elif self.graph_pooling == \"max\":\n","            self.pool = global_max_pool\n","        elif self.graph_pooling == \"attention\":\n","            self.pool = GlobalAttention(gate_nn = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, 1)))\n","        elif self.graph_pooling == \"set2set\":\n","            self.pool = Set2Set(emb_dim, processing_steps = 2)\n","        else:\n","            raise ValueError(\"Invalid graph pooling type.\")\n","\n","        self.graph_pred_linear_list = torch.nn.ModuleList()\n","\n","        if graph_pooling == \"set2set\":\n","            for i in range(max_seq_len):\n","                 self.graph_pred_linear_list.append(torch.nn.Linear(2*emb_dim, self.num_vocab))\n","\n","        else:\n","            for i in range(max_seq_len):\n","                 self.graph_pred_linear_list.append(torch.nn.Linear(emb_dim, self.num_vocab))\n","\n","    def forward(self, batched_data):\n","        x, edge_index, edge_attr, node_depth, batch = batched_data.x, batched_data.edge_index, batched_data.edge_attr, batched_data.node_depth, batched_data.batch\n","        # Embed the nodes of the AST\n","        x = self.node_encoder(x, node_depth.view(-1,))\n","        # DiffPool Layers\n","        z, mask = to_dense_batch(x, batch, max_num_nodes=self.max_num_nodes)\n","        s = to_dense_adj(edge_index, batch, max_num_nodes=self.max_num_nodes)\n","        for layer in range(len(self.diff_pool_layers)):\n","            if (mask is not None):\n","              z, s = self.diff_pool_layers[layer](z, s, mask)\n","              mask = None\n","            else:\n","              z, s = self.diff_pool_layers[layer](z, s)\n","\n","        # DiffPool Layeres without node_num limit\n","        # z, mask = to_dense_batch(x, batch)\n","        # s = to_dense_adj(edge_index, batch)\n","        # for layer in range(len(self.diff_pool_layers)):\n","        #     z, s = self.diff_pool_layers[layer](z, s)\n","\n","        # Final GNN and pooling\n","        x = self.final_gnn(z, s)\n","        del z, s, mask\n","        graph_emb = self.pool(x, batch=None)\n","\n","        pred_list = []\n","\n","        for i in range(self.max_seq_len):\n","            pred_list.append(self.graph_pred_linear_list[i](graph_emb))\n","\n","        return pred_list\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8FPK09rhzaIi"},"source":["# Main Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qGE0z5mYzfze"},"outputs":[],"source":["import numpy as np\n","import argparse\n","from torchvision import transforms\n","import torch.optim as optim\n","\n","multicls_criterion = torch.nn.CrossEntropyLoss()\n","\n","def train(model, device, loader, optimizer):\n","    model.train()\n","\n","    loss_accum = 0\n","    iter = 0\n","    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n","        batch = batch.to(device)\n","        iter += 1\n","\n","        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n","            pass\n","        else:\n","            optimizer.zero_grad()\n","            pred_list = model(batch)\n","            # if (iter % 100 == 1):\n","            #     print(\"after pred\", iter, \" memory use:\", torch.cuda.memory_allocated() / 1e6, \"MB\")\n","\n","            loss = 0\n","            for i in range(len(pred_list)):\n","                loss += multicls_criterion(pred_list[i].to(torch.float32), batch.y_arr[:,i])\n","\n","            loss = loss / len(pred_list)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            # loss_accum += loss.item()\n","            loss_accum += float(loss)\n","            del pred_list\n","            del loss\n","\n","    print('Average training loss: {}'.format(loss_accum / (step + 1)))\n","\n","\n","def eval(model, device, loader, evaluator, arr_to_seq):\n","    model.eval()\n","    seq_ref_list = []\n","    seq_pred_list = []\n","\n","    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n","        batch = batch.to(device)\n","\n","        if batch.x.shape[0] == 1:\n","            pass\n","        else:\n","            with torch.no_grad():\n","                pred_list = model(batch)\n","\n","            mat = []\n","            for i in range(len(pred_list)):\n","                mat.append(torch.argmax(pred_list[i], dim = 1).view(-1,1))\n","            mat = torch.cat(mat, dim = 1)\n","\n","            seq_pred = [arr_to_seq(arr) for arr in mat]\n","\n","            # PyG = 1.4.3\n","            # seq_ref = [batch.y[i][0] for i in range(len(batch.y))]\n","\n","            # PyG >= 1.5.0\n","            seq_ref = [batch.y[i] for i in range(len(batch.y))]\n","\n","            seq_ref_list.extend(seq_ref)\n","            seq_pred_list.extend(seq_pred)\n","\n","    input_dict = {\"seq_ref\": seq_ref_list, \"seq_pred\": seq_pred_list}\n","\n","    return evaluator.eval(input_dict)\n","\n","def main():\n","    print (\"Starting Training\")\n","    # Training settings\n","    print(args)\n","\n","    device = torch.device(\"cuda:\" + str(args['device'])) if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","    # ### automatic dataloading and splitting\n","    # dataset = PygGraphPropPredDataset(name = args.dataset)\n","\n","    seq_len_list = np.array([len(seq) for seq in dataset.data.y])\n","    print('Target seqence less or equal to {} is {}%.'.format(args['max_seq_len'], np.sum(seq_len_list <= args['max_seq_len']) / len(seq_len_list)))\n","\n","    split_idx = dataset.get_idx_split()\n","\n","    if args['random_split']:\n","        print('Using random split')\n","        perm = torch.randperm(len(dataset))\n","        num_train, num_valid, num_test = len(split_idx['train']), len(split_idx['valid']), len(split_idx['test'])\n","        split_idx['train'] = perm[:num_train]\n","        split_idx['valid'] = perm[num_train:num_train+num_valid]\n","        split_idx['test'] = perm[num_train+num_valid:]\n","\n","        assert(len(split_idx['train']) == num_train)\n","        assert(len(split_idx['valid']) == num_valid)\n","        assert(len(split_idx['test']) == num_test)\n","\n","\n","    print(split_idx['train'])\n","    print(split_idx['valid'])\n","    print(split_idx['test'])\n","\n","    print(len(split_idx['train']))\n","    #shrink the train set\n","    # split_idx['train'] = split_idx['train'][:len(split_idx['train'])//10]\n","    # print(len(split_idx['train']))\n","\n","\n","    ### building vocabulary for sequence predition. Only use training data.\n","\n","    vocab2idx, idx2vocab = get_vocab_mapping([dataset.data.y[i] for i in split_idx['train']], args['num_vocab'])\n","\n","    ### set the transform function\n","    # augment_edge: add next-token edge as well as inverse edges. add edge attributes.\n","    # encode_y_to_arr: add y_arr to PyG data object, indicating the array representation of a sequence.\n","    dataset.transform = transforms.Compose([augment_edge, lambda data: encode_y_to_arr(data, vocab2idx, args['max_seq_len'])])\n","\n","    ### automatic evaluator. takes dataset name as input\n","    evaluator = Evaluator(args['dataset'])\n","\n","    train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args['batch_size'], shuffle=True, num_workers = args['num_workers'])\n","    valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args['batch_size'], shuffle=False, num_workers = args['num_workers'])\n","    test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=args['batch_size'], shuffle=False, num_workers = args['num_workers'])\n","\n","    nodetypes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'typeidx2type.csv.gz'))\n","    nodeattributes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'attridx2attr.csv.gz'))\n","\n","    print(nodeattributes_mapping)\n","\n","    ### Encoding node features into emb_dim vectors.\n","    ### The following three node features are used.\n","    # 1. node type\n","    # 2. node attribute\n","    # 3. node depth\n","    node_encoder = ASTNodeEncoder(args['emb_dim'], num_nodetypes = len(nodetypes_mapping['type']), num_nodeattributes = len(nodeattributes_mapping['attr']), max_depth = 20)\n","\n","    # if args.gnn == 'gcn':\n","    model = GNN(num_vocab = len(vocab2idx), max_seq_len = args['max_seq_len'],\n","                    node_encoder = node_encoder,\n","                    gnn_num_layers = args['num_layer'],\n","                    diff_pool_node_number_list = args['diff_pool_layers'],\n","                    emb_dim = args['emb_dim'],\n","                    drop_ratio = args['drop_ratio'],\n","                    graph_pooling = \"sum\",\n","                    max_num_nodes=args['max_num_nodes']).to(device)\n","    param_size = 0\n","    for param in model.parameters():\n","        param_size += param.nelement() * param.element_size()\n","    buffer_size = 0\n","    for buffer in model.buffers():\n","        buffer_size += buffer.nelement() * buffer.element_size()\n","\n","    size_all_mb = (param_size + buffer_size) / 1024**2\n","    print('model size: {:.3f}MB'.format(size_all_mb))\n","\n","\n","    # elif args.gnn == 'gin-virtual':\n","    #     model = GNN(num_vocab = len(vocab2idx), max_seq_len = args.max_seq_len, node_encoder = node_encoder, num_layer = args.num_layer, gnn_type = 'gin', emb_dim = args.emb_dim, drop_ratio = args.drop_ratio, virtual_node = True).to(device)\n","    # elif args.gnn == 'gcn':\n","    #     model = GNN(num_vocab = len(vocab2idx), max_seq_len = args.max_seq_len, node_encoder = node_encoder, num_layer = args.num_layer, gnn_type = 'gcn', emb_dim = args.emb_dim, drop_ratio = args.drop_ratio, virtual_node = False).to(device)\n","    # elif args.gnn == 'gcn-virtual':\n","    #     model = GNN(num_vocab = len(vocab2idx), max_seq_len = args.max_seq_len, node_encoder = node_encoder, num_layer = args.num_layer, gnn_type = 'gcn', emb_dim = args.emb_dim, drop_ratio = args.drop_ratio, virtual_node = True).to(device)\n","    # else:\n","    #     raise ValueError('Invalid GNN type')\n","\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    print(f'#Params: {sum(p.numel() for p in model.parameters())}')\n","\n","    valid_curve = []\n","    test_curve = []\n","    train_curve = []\n","\n","    best_val_f1 = -1\n","\n","    for epoch in range(1, args['epochs'] + 1):\n","        print(\"=====Epoch {}\".format(epoch))\n","        print('Training...')\n","        train(model, device, train_loader, optimizer)\n","\n","        print('Evaluating...')\n","        # train_perf = eval(model, device, train_loader, evaluator, arr_to_seq = lambda arr: decode_arr_to_seq(arr, idx2vocab))\n","        valid_perf = eval(model, device, valid_loader, evaluator, arr_to_seq = lambda arr: decode_arr_to_seq(arr, idx2vocab))\n","        test_perf = eval(model, device, test_loader, evaluator, arr_to_seq = lambda arr: decode_arr_to_seq(arr, idx2vocab))\n","\n","        # print({'Train': train_perf, 'Validation': valid_perf, 'Test': test_perf})\n","        print({'Validation': valid_perf, 'Test': test_perf})\n","        val_f1 = valid_perf[dataset.eval_metric]\n","        if (val_f1 > best_val_f1):\n","            best_val_f1 = val_f1\n","            torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            }, args['model_save_path'])\n","\n","        # train_curve.append(train_perf[dataset.eval_metric])\n","        valid_curve.append(valid_perf[dataset.eval_metric])\n","        test_curve.append(test_perf[dataset.eval_metric])\n","\n","    print('F1')\n","    best_val_epoch = np.argmax(np.array(valid_curve))\n","    # best_train = max(train_curve)\n","    print('Finished training!')\n","    print('Best validation score: {}'.format(valid_curve[best_val_epoch]))\n","    print('Test score: {}'.format(test_curve[best_val_epoch]))\n","    if not args['eval_results_path'] == '':\n","        result_dict = {'Val': valid_curve, 'Test': test_curve}\n","        torch.save(result_dict, args['eval_results_path'])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701867632850,"user":{"displayName":"昂国昊","userId":"00863862249147242163"},"user_tz":480},"id":"7AAKnF_TKOL5","outputId":"f0738ccd-f771-4bdc-fa78-054da48cb05c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'F1'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataset.eval_metric"]},{"cell_type":"markdown","metadata":{"id":"w7-ct3-xagJ2"},"source":["# Run"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","referenced_widgets":["e1497452bb454946bd357b6a7eeb3c86","597da38b1ce7450eae7a799a655da84e","36162217d3284e45a5d77b9a9b140e1c","18bdd53310b14c2794fe06475328ece7","8e7e887fd58146279e409c6b519f6ca8","027e772236364f9aa0e308d681ba863c","83a0f915e4864f0988e50d98d4028979","346d2552d7744dd1b032851bf4fa5156","e3fa0d68831e4e709191cd603c1a2357","e6515fcdd2d044889ead49a5f484bb5d","07e3baad7b054540aa994baf410fa120","42d09aacc2f243be97379731bef803c0","69d10229b4214184a968921f44427f8c","6cbb30a01b1b401688816c9067d336c2","71c253fa754340b1a5d80bda13ffdaba","a3cd641f2a5e43bcb7e88500e50865fa","60add391d7824104b1a08eb690aa486f","81dc9f9738b849ae968a1b5df9ef51f2","ebb34b9c616648f586e6a6060a3f2e88","77f2a84e4fa547e58b89298f7ff0eced","3db265f43cd74022aed6a62446bbcf3f","e958c703277042dfa71c4090c3df9868","77f8a0898e0b47feb198253f4a960f38","8201a18ef1fd47d886fc4ff2b8806422","743d1749576e4638ae05b8ff9b5d90f8","8c0c436329df4aaaab68e198baa77cf6","477ffa8c6b954d50972adb0b258f8bcb","c95d2c65f3c34d0b8e2254a8ccb36cf2","933e1905710743628efe1a2bd2be529e","c7f73bc6b8724802aa8246a50485d1eb","c75fb1a649fb4e09afb74c80902df1ee","f758f297930e45daa9da3abe74211edb","ec4b54073d03477d9615d913e386c1f7","5fdfef7c930448b0bc02744536d9bf53","e98c25524cab4d7e9ba274e001d1d61a","42d50a14cd42442ea6531f0b46103ac8","85cfc12a7ec947e9a5197863ac26bc77","f52f13a60be74c65a35f660f1e476c83","0f5f2d75f1d6473fb23c2c4acf1dffd0","56e61ce0af8a4b83a62cebd4210383bb","fcf5e7027cda48a599d999ec439e9839","19603b805b694010abceeae2ec5f0a41","93f88404f3644c70961a7d1f14fe0660","be75c04363314fcb9cb5878846875286","5780086a80f4455f825d8cde584fc4b9","b4574bd65e76481097154d0e93b18613","19f06ede01cf4c1e87cff2dff1e6e026","f65de93d4edf40dc82365bafa73ae05f","009b92000a0646139e637da71e68c9b8","2d0cd635835b45ce959e47ee2f7980e1","ce3b20a7ebcc4a3098a66cff1451a5c6","f6ae91b87dd14251b2980eb39d1303ed","2a104501789448788b75cf4ac02a8b03","330d19c8d3864d1f8d2e4acfb26a1a67","e43bb8c89e7b4cabbe338a54dca991ff","def01c83f0904704bdd51e8015323732","1604c94dd055405aae6cc63264c435c8","2974cabbca4e4b5ea51db584181b11df","0172a849c79b4128b5a0fa484f0e7afa","f84b9632113844ed83b6fe556f515ef6","4834059618fc4ac4a21ceab2ffc37a3a","1861d086ea6a442abf596dd3ccb03000","1912e82b5b204891a4ba096141069ea6","def5181b374844b2b768ad20da040166","76b6aa5448c94e618518851716740b90","8851aa54ae0c43eab78136c147e26f1c","d83fce945c534cdab675a4e88fd81031","70bf816d3b6e4c2e9c7166bc0876554f","cacee6e7b751497582d8c2766ebedd44","1909c554572647e18b86f4f41cba1667","1eccb8db712e4e78881e3b1edb1f3598","0e5844a55b8244bfb06ccce722e61294","a5aa55936c5042f3899b544fa73bdbc0","775d9770bab344b4b0d356834c29531a","afa10766c060442f826d634d783d096c","7a913dabc7574671b80cc0f24cf96de4","a0194e040ef24490a5cf391c911b2922","c7f53e8ae28e4bc1820408bb7e1ad168","4e918b1088b64b7faf4e002e38ff67ba","fdfd7d74ba374a8fa912aba31883e042","b38beb064602400d953c23551bc9a8cb","acbe1747dacd4b5db46734e5e39451e2","a5e4da1c63804dcda1fb69298aa04670","7dcdd525416e441181e06ba2a0c53dad","35a98af887a24685965cf5e656de0313","fe7d200c20a34af8ad8a81698dcdb662","8c77bb343222476abb12a0210b788e9b","97c71bb12f4f4b8382f3f0f091ef5174","563cda7a6cd8475386d23b1fd950dac1","f25ca878fa214f47bda7a49050ba80c8","e52f59e1a04f4c75a3de9103c8a9a8c6"]},"id":"3e1hkOh0nJtj","outputId":"080d17b5-8d6f-4945-8218-91537c64dc3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting Training\n","{'device': 0, 'num_layer': 3, 'emb_dim': 256, 'drop_ratio': 0.5, 'batch_size': 64, 'lr': 0.01, 'epochs': 50, 'num_vocab': 5000, 'max_seq_len': 5, 'diff_pool_layers': [(128, 5), (32, 3)], 'max_num_nodes': 512, 'random_split': False, 'dataset': 'ogbg-code2', 'num_workers': 0, 'model_save_path': 'best_model_params', 'eval_results_path': 'eval_results'}\n","Target seqence less or equal to 5 is 0.9874166466036873%.\n","tensor([     0,      1,      2,  ..., 407973, 407974, 407975])\n","tensor([407976, 407977, 407978,  ..., 430790, 430791, 430792])\n","tensor([430793, 430794, 430795,  ..., 452738, 452739, 452740])\n","407976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Coverage of top 5000 vocabulary:\n","0.9025832389087423\n","       attr idx      attr\n","0             0       NaN\n","1             1       NaN\n","2             2        \\t\n","3             3        \\n\n","4             4      \\n\\t\n","...         ...       ...\n","10025     10025         |\n","10026     10026         }\n","10027     10027         ~\n","10028     10028  __NONE__\n","10029     10029   __UNK__\n","\n","[10030 rows x 2 columns]\n","model size: 38.909MB\n","#Params: 10192466\n","=====Epoch 1\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1497452bb454946bd357b6a7eeb3c86","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 3.184906141991709\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"597da38b1ce7450eae7a799a655da84e","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36162217d3284e45a5d77b9a9b140e1c","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.08590086339133103, 'recall': 0.04292326593023441, 'F1': 0.05477109071797243}, 'Test': {'precision': 0.08449517040277019, 'recall': 0.041386476983114484, 'F1': 0.05332192765216275}}\n","=====Epoch 2\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18bdd53310b14c2794fe06475328ece7","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.9284559424531227\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e7e887fd58146279e409c6b519f6ca8","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"027e772236364f9aa0e308d681ba863c","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.12361397203839243, 'recall': 0.05710840427389491, 'F1': 0.0748175441452384}, 'Test': {'precision': 0.12381538181155459, 'recall': 0.05872860382838513, 'F1': 0.07632004257209286}}\n","=====Epoch 3\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83a0f915e4864f0988e50d98d4028979","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.833876733742508\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"346d2552d7744dd1b032851bf4fa5156","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3fa0d68831e4e709191cd603c1a2357","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.12400111028326831, 'recall': 0.06352947294241065, 'F1': 0.0799531639563195}, 'Test': {'precision': 0.12525059230909422, 'recall': 0.06449266086362859, 'F1': 0.08104596763016665}}\n","=====Epoch 4\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6515fcdd2d044889ead49a5f484bb5d","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.772654317706239\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07e3baad7b054540aa994baf410fa120","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42d09aacc2f243be97379731bef803c0","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.12614132737286524, 'recall': 0.06376535596196374, 'F1': 0.08062229049869844}, 'Test': {'precision': 0.12507973391653, 'recall': 0.06394851756388115, 'F1': 0.08068183133109322}}\n","=====Epoch 5\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69d10229b4214184a968921f44427f8c","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.726030705321069\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cbb30a01b1b401688816c9067d336c2","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71c253fa754340b1a5d80bda13ffdaba","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.12131305605469606, 'recall': 0.06374161635260817, 'F1': 0.07933843534930445}, 'Test': {'precision': 0.12402041188263167, 'recall': 0.0660424278453256, 'F1': 0.08198758721585402}}\n","=====Epoch 6\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3cd641f2a5e43bcb7e88500e50865fa","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.6932570677364573\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60add391d7824104b1a08eb690aa486f","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81dc9f9738b849ae968a1b5df9ef51f2","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.1267549049685176, 'recall': 0.0665761778846321, 'F1': 0.08296428557199034}, 'Test': {'precision': 0.13056618674442622, 'recall': 0.07079500319658877, 'F1': 0.08713575521940749}}\n","=====Epoch 7\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebb34b9c616648f586e6a6060a3f2e88","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.666482454823513\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77f2a84e4fa547e58b89298f7ff0eced","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3db265f43cd74022aed6a62446bbcf3f","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.11847525967480388, 'recall': 0.06458966824374196, 'F1': 0.07944215918095043}, 'Test': {'precision': 0.12405838041431261, 'recall': 0.0685653825347647, 'F1': 0.0840627367691337}}\n","=====Epoch 8\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e958c703277042dfa71c4090c3df9868","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.6441842813678815\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77f8a0898e0b47feb198253f4a960f38","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8201a18ef1fd47d886fc4ff2b8806422","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.13609004981665718, 'recall': 0.07045128214760506, 'F1': 0.08801144510045766}, 'Test': {'precision': 0.1391470749043193, 'recall': 0.0736179092863073, 'F1': 0.0916643885547658}}\n","=====Epoch 9\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"743d1749576e4638ae05b8ff9b5d90f8","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.62604159525329\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c0c436329df4aaaab68e198baa77cf6","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"477ffa8c6b954d50972adb0b258f8bcb","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.13202509824546027, 'recall': 0.07224884884634195, 'F1': 0.08869733719845478}, 'Test': {'precision': 0.13385426158799588, 'recall': 0.07397145055701643, 'F1': 0.09064926452159913}}\n","=====Epoch 10\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c95d2c65f3c34d0b8e2254a8ccb36cf2","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.6090960788352815\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"933e1905710743628efe1a2bd2be529e","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7f73bc6b8724802aa8246a50485d1eb","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.1367255408978685, 'recall': 0.07644660309668856, 'F1': 0.09303088549264646}, 'Test': {'precision': 0.1421997448514671, 'recall': 0.08087868584041356, 'F1': 0.09801490654415752}}\n","=====Epoch 11\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c75fb1a649fb4e09afb74c80902df1ee","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.5917793906529742\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f758f297930e45daa9da3abe74211edb","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec4b54073d03477d9615d913e386c1f7","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.1444427400622343, 'recall': 0.07287710499898781, 'F1': 0.09195698556701318}, 'Test': {'precision': 0.14493347913249496, 'recall': 0.07523276517945737, 'F1': 0.09414181716669415}}\n","=====Epoch 12\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fdfef7c930448b0bc02744536d9bf53","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.5797641641018436\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e98c25524cab4d7e9ba274e001d1d61a","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42d50a14cd42442ea6531f0b46103ac8","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.13886575798746548, 'recall': 0.07606002138477923, 'F1': 0.09300893722377704}, 'Test': {'precision': 0.14469427738290505, 'recall': 0.07977597119887989, 'F1': 0.09770504716513466}}\n","=====Epoch 13\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85cfc12a7ec947e9a5197863ac26bc77","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.563658599479526\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f52f13a60be74c65a35f660f1e476c83","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f5f2d75f1d6473fb23c2c4acf1dffd0","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.14288323033995118, 'recall': 0.08008685044776555, 'F1': 0.09725931862277569}, 'Test': {'precision': 0.15053004070226594, 'recall': 0.08648631252513155, 'F1': 0.10435860663444042}}\n","=====Epoch 14\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56e61ce0af8a4b83a62cebd4210383bb","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.553486994014067\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcf5e7027cda48a599d999ec439e9839","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19603b805b694010abceeae2ec5f0a41","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.13682780383047727, 'recall': 0.07358111920170911, 'F1': 0.09045229434193802}, 'Test': {'precision': 0.14106068890103882, 'recall': 0.07916055554109136, 'F1': 0.09603142058718876}}\n","=====Epoch 15\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93f88404f3644c70961a7d1f14fe0660","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.5397970588160494\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be75c04363314fcb9cb5878846875286","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5780086a80f4455f825d8cde584fc4b9","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.1452754525134768, 'recall': 0.07790398901960456, 'F1': 0.09619731458930302}, 'Test': {'precision': 0.1499832938460604, 'recall': 0.08289448942811435, 'F1': 0.10139565090357872}}\n","=====Epoch 16\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4574bd65e76481097154d0e93b18613","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.5302603231691845\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19f06ede01cf4c1e87cff2dff1e6e026","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f65de93d4edf40dc82365bafa73ae05f","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.13917254678529167, 'recall': 0.07753302501406985, 'F1': 0.09431699839509806}, 'Test': {'precision': 0.14946692181519955, 'recall': 0.08414435925029144, 'F1': 0.10222622157422596}}\n","=====Epoch 17\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"009b92000a0646139e637da71e68c9b8","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.518110799434138\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d0cd635835b45ce959e47ee2f7980e1","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce3b20a7ebcc4a3098a66cff1451a5c6","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.14615564418343047, 'recall': 0.08240178410555761, 'F1': 0.09981338753964428}, 'Test': {'precision': 0.15136534839924667, 'recall': 0.0866935122265904, 'F1': 0.10467379146985488}}\n","=====Epoch 18\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6ae91b87dd14251b2980eb39d1303ed","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.5102627125908348\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a104501789448788b75cf4ac02a8b03","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"330d19c8d3864d1f8d2e4acfb26a1a67","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.14376707425749805, 'recall': 0.08400689474778969, 'F1': 0.10049611435639398}, 'Test': {'precision': 0.15201081343782272, 'recall': 0.09241656324761846, 'F1': 0.10907210234028165}}\n","=====Epoch 19\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e43bb8c89e7b4cabbe338a54dca991ff","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.500724945629344\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"def01c83f0904704bdd51e8015323732","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1604c94dd055405aae6cc63264c435c8","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.147291493184906, 'recall': 0.0840935051907134, 'F1': 0.10138183973482216}, 'Test': {'precision': 0.15311949456290624, 'recall': 0.09084699838868783, 'F1': 0.10808893433278342}}\n","=====Epoch 20\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2974cabbca4e4b5ea51db584181b11df","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.494167191505432\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0172a849c79b4128b5a0fa484f0e7afa","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f84b9632113844ed83b6fe556f515ef6","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.14823742531153672, 'recall': 0.08382949986469292, 'F1': 0.1015854928551602}, 'Test': {'precision': 0.1553520442257457, 'recall': 0.09089294031202177, 'F1': 0.10881021809124597}}\n","=====Epoch 21\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4834059618fc4ac4a21ceab2ffc37a3a","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.483883600571576\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1861d086ea6a442abf596dd3ccb03000","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1912e82b5b204891a4ba096141069ea6","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.14627251610641187, 'recall': 0.08483539841847243, 'F1': 0.10178198693779182}, 'Test': {'precision': 0.15421298827531743, 'recall': 0.0924456905354937, 'F1': 0.10965197222031557}}\n","=====Epoch 22\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"def5181b374844b2b768ad20da040166","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.4755208687501797\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76b6aa5448c94e618518851716740b90","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8851aa54ae0c43eab78136c147e26f1c","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.1556660969160421, 'recall': 0.0873857107378166, 'F1': 0.10592655750651982}, 'Test': {'precision': 0.15954377012332177, 'recall': 0.09234247037008109, 'F1': 0.11095848747571001}}\n","=====Epoch 23\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d83fce945c534cdab675a4e88fd81031","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.468990633945839\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70bf816d3b6e4c2e9c7166bc0876554f","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cacee6e7b751497582d8c2766ebedd44","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15020233451666154, 'recall': 0.08575712136105701, 'F1': 0.10330643508318049}, 'Test': {'precision': 0.15906916347731, 'recall': 0.0926842413959691, 'F1': 0.11111226824731472}}\n","=====Epoch 24\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1909c554572647e18b86f4f41cba1667","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.462267612475975\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eccb8db712e4e78881e3b1edb1f3598","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e5844a55b8244bfb06ccce722e61294","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15034111992520197, 'recall': 0.0864520223364506, 'F1': 0.10372219683040562}, 'Test': {'precision': 0.15881477431504767, 'recall': 0.09389918016899974, 'F1': 0.11178264787477472}}\n","=====Epoch 25\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5aa55936c5042f3899b544fa73bdbc0","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.456142645106596\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"775d9770bab344b4b0d356834c29531a","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afa10766c060442f826d634d783d096c","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15533739463265692, 'recall': 0.08727283889553249, 'F1': 0.10571218480233688}, 'Test': {'precision': 0.16178391349249743, 'recall': 0.09469163766594056, 'F1': 0.11328649101339096}}\n","=====Epoch 26\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a913dabc7574671b80cc0f24cf96de4","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.4505090857674094\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0194e040ef24490a5cf391c911b2922","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7f53e8ae28e4bc1820408bb7e1ad168","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15500869234927173, 'recall': 0.09114870839133452, 'F1': 0.10873165757462554}, 'Test': {'precision': 0.16088405929165905, 'recall': 0.09749859697235312, 'F1': 0.11506700804814528}}\n","=====Epoch 27\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e918b1088b64b7faf4e002e38ff67ba","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.4430982690885954\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdfd7d74ba374a8fa912aba31883e042","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b38beb064602400d953c23551bc9a8cb","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15512556427225316, 'recall': 0.0878459287178663, 'F1': 0.10614631846169734}, 'Test': {'precision': 0.16396330721098354, 'recall': 0.09460810689624248, 'F1': 0.1139203583913808}}\n","=====Epoch 28\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acbe1747dacd4b5db46734e5e39451e2","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.4375856330161003\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5e4da1c63804dcda1fb69298aa04670","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dcdd525416e441181e06ba2a0c53dad","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.1436940293056347, 'recall': 0.08608495406168193, 'F1': 0.10189259470278009}, 'Test': {'precision': 0.14904167426037299, 'recall': 0.09280449315987861, 'F1': 0.10848149278985801}}\n","=====Epoch 29\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35a98af887a24685965cf5e656de0313","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.4341017691668343\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe7d200c20a34af8ad8a81698dcdb662","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c77bb343222476abb12a0210b788e9b","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15012928956479818, 'recall': 0.09080724063302842, 'F1': 0.1072342708447367}, 'Test': {'precision': 0.15759598444808942, 'recall': 0.09757757151824947, 'F1': 0.114298922732493}}\n","=====Epoch 30\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97c71bb12f4f4b8382f3f0f091ef5174","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average training loss: 2.4275282937779146\n","Evaluating...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"563cda7a6cd8475386d23b1fd950dac1","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/357 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f25ca878fa214f47bda7a49050ba80c8","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/343 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Validation': {'precision': 0.15714890943886867, 'recall': 0.09389248548318538, 'F1': 0.11149807543943496}, 'Test': {'precision': 0.16388357329445352, 'recall': 0.1018130154680182, 'F1': 0.11908899652885437}}\n","=====Epoch 31\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e52f59e1a04f4c75a3de9103c8a9a8c6","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/6375 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":[" main()"]},{"cell_type":"markdown","metadata":{"id":"aTqC6Q1QWxuN"},"source":["# Some random exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6WvYngWbjE0"},"outputs":[],"source":["import networkx as nx\n","import torch_geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UX11FbYG-8j3"},"outputs":[],"source":["print(len(train_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5896zPkv-_hw"},"outputs":[],"source":["print(len(valid_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aTPtRfz_Bna"},"outputs":[],"source":["print(len(test_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sjlacyXEYlJ-"},"outputs":[],"source":["dataset[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaTPJMZSZ0zN"},"outputs":[],"source":["G = torch_geometric.utils.to_networkx(dataset[0])\n","nx.draw(G, with_labels = True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AaMSUeiAaYox"},"outputs":[],"source":["print(G.number_of_edges(), G.number_of_nodes())\n","G.number_of_edges() / G.number_of_nodes()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIWbOF76fhr2"},"outputs":[],"source":["dataset[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1B9YQ2GJb23t"},"outputs":[],"source":["for d in dataset[:1]:\n","  for pair in zip(d.x, d.node_is_attributed):\n","    print(pair)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ6Hvv9bd2gG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["xLMap4xcvGwG","6bo9YEJuQ6P4","8aQf6gJSv9lx","aTqC6Q1QWxuN"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}